admin_secret: AQBSV4xaAAAAABAA3VUTiOZTHecau2SnAEVPYQ==
ceph_conf_overrides:
  global: {osd_pool_default_pg_num: 100, osd_pool_default_pgp_num: 100, osd_pool_default_size: 1,
    rgw_keystone_accepted_roles: 'Member, admin', rgw_keystone_admin_domain: default,
    rgw_keystone_admin_password: RtYPg7AUdsZCGv4Z4rF8FvnaR, rgw_keystone_admin_project: service,
    rgw_keystone_admin_user: swift, rgw_keystone_api_version: 3, rgw_keystone_implicit_tenants: 'true',
    rgw_keystone_url: 'http://control0:5000', rgw_s3_auth_use_keystone: 'true', rgw_keystone_revocation_interval: 0}
cluster: ceph
ceph_docker_image: ceph/daemon
ceph_docker_image_tag: latest
ceph_docker_registry: docker.io
ceph_origin: repository
ceph_repository: community
ceph_release: luminous
ceph_stable: true
# cephfs_data_pool:
#   name: 'manila_data'
#   pg_num: "{{ osd_pool_default_pg_num }}"
#   pgp_num: "{{ osd_pool_default_pg_num }}"
#   rule_name: "replicated_rule"
#   type: 1
#   erasure_profile: ""
#   expected_num_objects: ""
#   application: "cephfs"
#   size: "{{ osd_pool_default_size }}"
#   min_size: "{{ osd_pool_default_min_size }}"
# cephfs_metadata_pool:
#   name: 'manila_metadata'
#   pg_num: "{{ osd_pool_default_pg_num }}"
#   pgp_num: "{{ osd_pool_default_pg_num }}"
#   rule_name: "replicated_rule"
#   type: 1
#   erasure_profile: ""
#   expected_num_objects: ""
#   application: "cephfs"
#   size: "{{ osd_pool_default_size }}"
#   min_size: "{{ osd_pool_default_min_size }}"
# cephfs_pools:
#   - "{{ cephfs_data_pool }}"
#   - "{{ cephfs_metadata_pool }}"
cluster_network: 172.28.128.0/24
containerized_deployment: true
devices: [ /dev/vdb ]
docker: true
fsid: 6e008d48-1661-11e8-8546-008c3214218a
generate_fsid: false
ip_version: ipv4
ireallymeanit: 'yes'
journal_size: 4096
keys:
  - {key: AQAN0RdbAAAAABAA3CpSKRVDrENjkOSunEFZ0A==, mgr_cap: 'allow *', mds_cap: 'allow *', mode: '0600', mon_cap: 'allow r', name: client.openstack, osd_cap: "allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=backups, allow rwx pool=vms, allow rwx pool=images, allow rwx pool=metrics"}
  # - {key: AQAN0RdbAAAAABAAtV5Dq28z4H6XxwhaNEaFZg==, mds_cap: 'allow *', mgr_cap: 'allow *', mode: '0600', mon_cap: 'allow r, allow command \"auth del\", allow command \"auth caps\", allow command \"auth get\", allow command \"auth get-or-create\"', name: client.manila, osd_cap: 'allow rw'}
  - {key: AQAN0RdbAAAAABAAH5D3WgMN9Rxw3M8jkpMIfg==, mgr_cap: 'allow *', mds_cap: 'allow *', mode: '0600', mon_cap: 'allow rw', name: client.radosgw, osd_cap: 'allow rwx'}
monitor_interface: eth0
monitor_address_block: 192.168.121.0/24
monitor_secret: AQBSV4xaAAAAABAALqm4vRHcITs4/041TwluMg==
ntp_service_enabled: false
openstack_config: true
openstack_keys:
  - {key: AQAN0RdbAAAAABAA3CpSKRVDrENjkOSunEFZ0A==, mgr_cap: 'allow *', mds_cap: 'allow *', mode: '0600', mon_cap: 'allow r', name: client.openstack, osd_cap: "allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=backups, allow rwx pool=vms, allow rwx pool=images, allow rwx pool=metrics"}
  # - {key: AQAN0RdbAAAAABAAtV5Dq28z4H6XxwhaNEaFZg==, mds_cap: 'allow *', mgr_cap: 'allow *', mode: '0600', mon_cap: 'allow r, allow command \"auth del\", allow command \"auth caps\", allow command \"auth get\", allow command \"auth get-or-create\"', name: client.manila, osd_cap: 'allow rw'}
  - {key: AQAN0RdbAAAAABAAH5D3WgMN9Rxw3M8jkpMIfg==, mgr_cap: 'allow *', mds_cap: 'allow *', mode: '0600', mon_cap: 'allow rw', name: client.radosgw, osd_cap: 'allow rwx'}
openstack_pools:
- {name: images, pg_num: 100, rule_name: ''}
- {name: metrics, pg_num: 100, rule_name: ''}
- {name: backups, pg_num: 100, rule_name: ''}
- {name: vms, pg_num: 100, rule_name: ''}
- {name: volumes, pg_num: 100, rule_name: ''}
os_tuning_params:
  - { name: fs.file-max, value: 26234859 }
osd_objectstore: bluestore
lvm_volumes:
  - data: /dev/vdb
  #   data_vg: data-vg1
  #   db: db-lv1
  #   db_vg: db-vg1
  #   wal: wal-lv1
  #   wal_vg: wal-vg1
  # - data: data-lv2
  #   data_vg: data-vg2
  #   db: db-lv2
  #   db_vg: db-vg2
  #   wal: wal-lv2
  #   wal_vg: wal-vg2
ceph_osd_docker_run_script_path: /opt
public_network: 192.168.121.0/24
ceph_mon_docker_subnet: "{{ public_network }}"
pools: []
radosgw_address_block: 192.168.121.0/24
radosgw_civetweb_port: '8080'
radosgw_keystone_ssl: false
user_config: true
dashboard_enabled: True
