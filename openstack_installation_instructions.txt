Setup host machine
Configure virsh with custom values
Setup in-line Security Onion box to monitor internet network traffic from openstack cluster
Setup Security Onion dhcp w/ router advertisement
Vagrant setup virtual environment/hosts that we will deploy OpenStack to (multinode OpenStack deployment)
Set static IPs to machines
Transfer Vagrant keys to virtual deployment host
Setup virtual deployment host (kolla-ansible,pip packages, etc.)
Configure Ansible for more performance
Edit multinode/transfer to virtual deployment host



sudo yum install epel-release -y
sudo yum install ruby-devel libvirt-devel zlib-devel libpng-devel gcc qemu-kvm qemu-img libvirt libvirt-python libvirt-client virt-install bridge-utils git -y
sudo yum install https://releases.hashicorp.com/vagrant/2.2.5/vagrant_2.2.5_x86_64.rpm -y
vagrant plugin install vagrant-hostmanager
vagrant plugin install --plugin-version ">= 0.0.31" vagrant-libvirt

sudo gpasswd -a ${USER} libvirt
newgrp libvirt
sudo systemctl disable firewalld
sudo systemctl start nfs-server
sudo systemctl start rpcbind.service
sudo systemctl enable libvirtd --now

# configure libvirtd default storage location
sudo virsh pool-destroy default
sudo virsh pool-undefine default
sudo virsh pool-define-as --name default --type dir --target /openstack
sudo virsh pool-autostart default
sudo virsh pool-start default

sudo virsh pool-destroy storage
sudo virsh pool-undefine storage
sudo virsh pool-define-as --name storage --type dir --target /storage
sudo virsh pool-autostart storage
sudo virsh pool-start storage


cat << EOF > /etc/sysconfig/network-scripts/ifcfg-internal0
DEVICE="internal0"
BOOTPROTO="static"
ONBOOT="yes"
TYPE="Bridge"
NM_CONTROLLED="no"
IPV6INIT="no"
IPV6_AUTOCONF="no"
EOF



###
# Create bridge on team0 interface named: external0
###



cat << EOF > /tmp/temp.xml
<network>
<name>external</name>
<bridge name="external0"/>
<forward mode="bridge"/>
</network>
EOF
cat << EOF > /tmp/temp2.xml
<network>
<name>default</name>
<bridge name='internal0'/>
<forward mode="bridge"/>
</network>
EOF


sudo virsh net-define /tmp/temp.xml
sudo virsh net-start external
sudo virsh net-autostart external

sudo virsh net-undefine default
sudo virsh net-destroy default
sudo virsh net-define /tmp/temp2.xml
sudo virsh net-start default
sudo virsh net-autostart default

virt-install --name security_onion --cdrom /opt/securityOnion/securityonion-16.04.6.1.iso --graphics spice --graphics vnc --vcpus 4 --ram 8192 --os-type linux --os-variant ubuntu16.04 --disk size=50,format=raw,sparse=true --network network=default --network network=external

ssh onions@192.168.138.200
# Switch /etc/network/interfaces OPENSTACK_IFACE from manual to static
# And assign address, gateway, netmask

export INTERNET_IFACE='ens4'
export OPENSTACK_IFACE='ens3'
export OPENSTACK_EXT_ROUTER='10.4.4.1'
export OPENSTACK_EXT_DHCP_POOL='10.4.4.20,10.4.4.253'

### Write dnsmasq DHCP file for openstack network
cat << EOF > /opt/openstack-network.conf
strict-order
expand-hosts
pid-file=/opt/openstack-network.pid
except-interface=lo
bind-dynamic
interface=$OPENSTACK_IFACE
dhcp-option=option:router,$OPENSTACK_EXT_ROUTER
dhcp-range=$OPENSTACK_EXT_DHCP_POOL
dhcp-no-override
dhcp-authoritative
dhcp-lease-max=127
dhcp-hostsfile=/opt/openstack-network.hostsfile
addn-hosts=/opt/openstack-network.addnhosts
EOF

# TODO create systemd file for dnsmasq for persistance
# Get dnsmasq command for dhcp w/ router advertising on openstack "public/external" network
/usr/sbin/dnsmasq --conf-file=/opt/openstack-network.conf

sysctl -w net.ipv4.ip_forward=1
# https://unix.stackexchange.com/a/222065/341646
iptables -t nat -A POSTROUTING -o $INTERNET_IFACE -j MASQUERADE
iptables -A FORWARD -i $OPENSTACK_IFACE -o $INTERNET_IFACE -j ACCEPT
iptables -A FORWARD -i $INTERNET_IFACE -o $OPENSTACK_IFACE -m state --state RELATED,ESTABLISHED -j ACCEPT

exit # securityOnion vm

# Vagrant setup virtual machines
vagrant up

vagrant destroy -f; for _ in 1 2; do for i in operator compute0 compute1 control0 control1 control2; do vagrant up --provision $i; done; done

vagrant ssh operator
# Grab your customized inventory file and globals.yml
scp server@192.168.138.200:/home/server/res/* ~/
sudo setenforce permissive
sudo mkdir -p /etc/kolla
sudo chown $USER:$USER /etc/kolla
cp -r ~/openstack-virt-env/share/kolla-ansible/etc_examples/kolla/* /etc/kolla
# Make sure Ansible uses scp.
cat > ~vagrant/.ansible.cfg <<EOF
[defaults]
forks=100
remote_user = root

[ssh_connection]
scp_if_ssh=True
EOF
chown vagrant: ~vagrant/.ansible.cfg
mv ~/globals.yml /etc/kolla/

###
# External CEPH configurations
# https://docs.openstack.org/kolla-ansible/queens/reference/external-ceph-guide.html
###
rm -rvf /etc/kolla/config
mkdir -p /etc/kolla/config
cat << EOF > /etc/kolla/config/ceph.conf
# Please do not change this file directly since it is managed by Ansible and will be overwritten
[global]
cluster network = 172.28.128.0/24
fsid = 6e008d48-1661-11e8-8546-008c3214218a
mon host = [v2:192.168.121.174:3300,v1:192.168.121.174:6789],[v2:192.168.121.76:3300,v1:192.168.121.76:6789],[v2:192.168.121.201:3300,v1:192.168.121.201:6789]
mon initial members = storage0,storage1,storage2
osd pool default crush rule = -1
osd_pool_default_pg_num = 100
osd_pool_default_pgp_num = 100
osd_pool_default_size = 1
public network = 192.168.121.0/24
rgw_keystone_accepted_roles = Member, admin
rgw_keystone_admin_domain = default
rgw_keystone_admin_password = RtYPg7AUdsZCGv4Z4rF8FvnaR
rgw_keystone_admin_project = service
rgw_keystone_admin_user = swift
rgw_keystone_api_version = 3
rgw_keystone_implicit_tenants = true
rgw_keystone_revocation_interval = 0
rgw_keystone_url = http://control0:5000
rgw_s3_auth_use_keystone = true

[osd]
osd memory target = 4294967296

osd_memory_target = 1873113088
osd_memory_base = 962770944
osd_memory_cache_min = 1417942016
EOF

mkdir -p /etc/kolla/config/glance/
cp /etc/kolla/config/ceph.conf /etc/kolla/config/glance/ceph.conf
cat << EOF > /etc/kolla/config/glance/glance-api.conf
[glance_store]
stores = rbd
default_store = rbd
rbd_store_pool = images
rbd_store_user = glance
rbd_store_ceph_conf = /etc/ceph/ceph.conf
EOF
cat << EOF > /etc/kolla/config/glance/ceph.client.glance.keyring
[client.glance]
        key = AQAN0RdbAAAAABAA3CpSKRVDrENjkOSun0000w==
EOF

# [client.glance]
#         key = AQAU829dlEpVMhAAnm8Rncg4Rz1yHor66ANpeQ==
#         caps mon = "profile rbd"
#         caps osd = "profile rbd pool=images"

mkdir -p /etc/kolla/config/cinder/{cinder-backup,cinder-volume}
cp /etc/kolla/config/ceph.conf /etc/kolla/config/cinder/ceph.conf
cat << EOF > /etc/kolla/config/cinder/cinder-volume.conf
[DEFAULT]
enabled_backends = rbd-1

[rbd-1]
rbd_ceph_conf = /etc/ceph/ceph.conf
rbd_user = cinder
rbd_pool = volumes
rbd_secret_uuid = {{ cinder_rbd_secret_uuid }}
volume_backend_name = rbd-1
volume_driver = cinder.volume.drivers.rbd.RBDDriver
backend_host = rbd:volumes
EOF
cat << EOF > /etc/kolla/config/cinder/cinder-volume/ceph.client.cinder.keyring
[client.cinder]
        key = AQBclHBdZ8G6JRAAHEXhgmU7pQXf34Fxpeib3A==
EOF
cat << EOF > /etc/kolla/config/cinder/cinder-backup.conf
[DEFAULT]
backup_ceph_conf = /etc/ceph/ceph.conf
backup_ceph_user = cinder-backup
backup_ceph_chunk_size = 134217728
backup_ceph_pool = backups
backup_driver = cinder.backup.drivers.ceph
backup_ceph_stripe_unit = 0
backup_ceph_stripe_count = 0
restore_discard_excess_bytes = true
EOF
cp /etc/kolla/config/cinder/cinder-volume/ceph.client.cinder.keyring /etc/kolla/config/cinder/cinder-backup/ceph.client.cinder.keyring
cat << EOF > /etc/kolla/config/cinder/cinder-backup/ceph.client.cinder-backup.keyring
[client.cinder-backup]
        key = AQCZlHBdOTrfEBAAiC3Tg/RwEW1g0yyWCSbNjA==
EOF

mkdir -p /etc/kolla/config/nova
cp /etc/kolla/config/ceph.conf /etc/kolla/config/nova/ceph.conf
cp /etc/kolla/config/cinder/cinder-volume/ceph.client.cinder.keyring /etc/kolla/config/nova/ceph.client.nova.keyring
cp /etc/kolla/config/cinder/cinder-volume/ceph.client.cinder.keyring /etc/kolla/config/nova/ceph.client.cinder.keyring
cat << EOF > /etc/kolla/config/nova/nova-compute.conf
[libvirt]
images_rbd_pool = vms
images_type = rbd
images_rbd_ceph_conf = /etc/ceph/ceph.conf
rbd_user = cinder
EOF

# Then use this to verify if ansible can reach all hosts and verify syntax
ansible -i multinode all -m ping
kolla-genpwd

# kolla-ansible -i ./multinode bootstrap-servers
# kolla-ansible -i ./multinode prechecks
# kolla-ansible -i ./multinode pull
# kolla-ansible -i ./multinode deploy

kolla-ansible -i ./multinode bootstrap-servers && kolla-ansible -i ./multinode prechecks && kolla-ansible -i ./multinode pull && sleep 10 && kolla-ansible -i ./multinode deploy

pip install python-openstackclient
kolla-ansible post-deploy
ssh compute0 sudo docker exec -u root nova_compute ln -s /etc/ceph/ceph.client.nova.keyring ceph.client.cinder.keyring
ssh compute1 sudo docker exec -u root nova_compute ln -s /etc/ceph/ceph.client.nova.keyring ceph.client.cinder.keyring
. /etc/kolla/admin-openrc.sh
env | grep OS_PASSWORD && sleep 10 || sleep 60
bash init-runonce
